{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ed876",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abded3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_files(base_path):\n",
    "    root_dir = base_path+ \"/raw\"\n",
    "    dataframes = []\n",
    "    print(\"Loading all files from\", root_dir)\n",
    "    num_chunks = 4\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        fol1 = f\"{root_dir}/chunk_{i}/\"\n",
    "        hf_df = load_dataset(\n",
    "            \"parquet\",\n",
    "            data_files=os.path.join(fol1, \"*.parquet\"),\n",
    "            streaming=False\n",
    "        )['train']\n",
    "        dataframes.append(hf_df)\n",
    "                \n",
    "    print(\"Completed: loading all files from\", root_dir)\n",
    "    print(\"Concatenating all dataframes...\")\n",
    "\n",
    "    return concatenate_datasets(dataframes)\n",
    "    \n",
    "def extract_details_csqa(row):\n",
    "    output_gen = row['answer']\n",
    "    seed_data = row['user']\n",
    "    f1 = '''Generate 3 developmentally appropriate skill-based instruction-response pairs based on the following input:\n",
    "\n",
    "- Text:'''\n",
    "    f2 = '''Instructions:\n",
    "    - Consider the developmental stage'''\n",
    "    f3 = '''- Age Group:'''\n",
    "    f4 = '''- Stage:'''\n",
    "    f5 = '''- Skill:'''\n",
    "    f6 = '''- Sub-skill:'''\n",
    "    f7 = '''- Goal:'''\n",
    "    f8 = '''- Indicator:'''\n",
    "    f9 = '''\\n\\nInstructions:\\n- '''\n",
    "    s = seed_data.find(f1)\n",
    "    e = seed_data.find(f2)\n",
    "    m = seed_data[len(f1):e].strip()\n",
    "    s1 = m.find(f3)\n",
    "    context = m[:s1].strip()\n",
    "    s2 = m.find(f4)\n",
    "    age_group = m[s1+len(f3):s2].strip()\n",
    "    s3 = m.find(f5)\n",
    "    stage = m[s2+len(f4):s3].strip()\n",
    "    s4 = m.find(f6)\n",
    "    skill = m[s3+len(f5):s4].strip()\n",
    "    s5 = m.find(f7)\n",
    "    sub_skill = m[s4+len(f6):s5].strip()\n",
    "    s6 = m.find(f8)\n",
    "    goal = m[s5+len(f7):s6].strip()\n",
    "    s7 = m.find(f9)\n",
    "    indicator = m[s6+len(f8):s7].strip()\n",
    "\n",
    "    return {\n",
    "            'context': context,\n",
    "            'age_group': age_group,\n",
    "            'stage': stage,\n",
    "            'skill': skill,\n",
    "            'sub_skill': sub_skill,\n",
    "            'goal': goal,\n",
    "            'indicator': indicator,\n",
    "            'output': output_gen,\n",
    "        }\n",
    "    \n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[“”]', '\"', text)  # Normalize fancy quotes\n",
    "    text = re.sub(r'[{}\\[\\]\\\\]+', '', text)  # Remove leftover brackets\n",
    "    text = re.sub(r'\\\\n', ' ', text)  # Remove escaped newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n",
    "    if re.search(r'[\",;]$', text):\n",
    "        text = text.rstrip('\",;')\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def extract_all_csqa(text):\n",
    "    raw = text['output']\n",
    "    pattern = r'\"instruction\"\\s*:\\s*\"([^\"]+)\"\\s*,\\s*\"response\"\\s*:\\s*\"([^\"]+?)\"'\n",
    "    matches = re.findall(pattern, raw)\n",
    "    if not matches:\n",
    "        return {\"qa\": [], \"qa_num\": 0}\n",
    "    res = {\n",
    "        \"qa\": [],\n",
    "        \"qa_num\": len(matches)\n",
    "    }\n",
    "    for idx, (q, a) in enumerate(matches, 1):\n",
    "        res[\"qa\"].append({\"question\": clean_text(q), \"answer\": clean_text(a)})\n",
    "    return res\n",
    "\n",
    "def extract_csqa(text):\n",
    "    raw = text['output']\n",
    "    match = re.search(r'\\{.*\\}', raw, re.DOTALL)\n",
    "    if not match:\n",
    "        return extract_all_csqa(text)\n",
    "    json_str = match.group()\n",
    "    json_str = json_str.replace('{{', '{').replace('}}', '}')\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        qa_pairs = data.get(\"skill_based_pairs\", [])\n",
    "        qa_pairs = [{\"question\": pair.get(\"instruction\", \"\").strip(), \"answer\": pair.get(\"response\", \"\").strip()} for pair in qa_pairs if isinstance(pair, dict)]\n",
    "        return {\"qa\": qa_pairs, \"qa_num\": len(qa_pairs)}\n",
    "    except json.JSONDecodeError:\n",
    "        return extract_all_csqa(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a617c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details_cqa(row):\n",
    "    output_gen = row['answer']\n",
    "    seed_data = row['user']\n",
    "    f1 = '''Generate 5 developmentally appropriate reading comprehension question-answer pairs based on the following input:\\n\\n- Text: '''\n",
    "    f2 = '''\\n- Age Group: '''\n",
    "    f3 = '''\\n- Stage: '''\n",
    "    f4 = '''\\n\\nInstructions:\\n- '''\n",
    "    s1 = seed_data.find(f1)\n",
    "    s2 = seed_data.find(f2)\n",
    "    s3 = seed_data.find(f3)\n",
    "    s4 = seed_data.find(f4)\n",
    "\n",
    "    context = seed_data[len(f1):s2].strip()\n",
    "    age_group = seed_data[s2 + len(f2):s3].strip()\n",
    "    stage = seed_data[s3 + len(f3):s4].strip()\n",
    "\n",
    "    return {\n",
    "        \"context\": context,\n",
    "        \"age_group\": age_group,\n",
    "        \"stage\": stage,\n",
    "        \"output\": output_gen,\n",
    "    }\n",
    "\n",
    "def extract_details_csqa(row):\n",
    "    output_gen = row['answer']\n",
    "    seed_data = row['user']\n",
    "    f1 = '''Generate 3 developmentally appropriate skill-based instruction-response pairs based on the following input:\n",
    "\n",
    "- Text:'''\n",
    "    f2 = '''Instructions:\n",
    "    - Consider the developmental stage'''\n",
    "    f3 = '''- Age Group:'''\n",
    "    f4 = '''- Stage:'''\n",
    "    f5 = '''- Skill:'''\n",
    "    f6 = '''- Sub-skill:'''\n",
    "    f7 = '''- Goal:'''\n",
    "    f8 = '''- Indicator:'''\n",
    "    f9 = '''\\n\\nInstructions:\\n- '''\n",
    "    s = seed_data.find(f1)\n",
    "    e = seed_data.find(f2)\n",
    "    m = seed_data[len(f1):e].strip()\n",
    "    s1 = m.find(f3)\n",
    "    context = m[:s1].strip()\n",
    "\n",
    "    return {\n",
    "            'context': context\n",
    "        }\n",
    "\n",
    "def extract_all_cqa(text):\n",
    "    raw = text['output']\n",
    "    pattern = r'\"question\"\\s*:\\s*\"([^\"]+)\"\\s*,\\s*\"answer\"\\s*:\\s*\"([^\"]+?)\"'\n",
    "    matches = re.findall(pattern, raw)\n",
    "    if not matches:\n",
    "        return {\"qa\": [], \"qa_num\": 0}\n",
    "    res = {\n",
    "        \"qa\": [],\n",
    "        \"qa_num\": len(matches)\n",
    "    }\n",
    "    for idx, (q, a) in enumerate(matches, 1):\n",
    "        res[\"qa\"].append({\"question\": clean_text(q), \"answer\": clean_text(a)})\n",
    "    return res\n",
    "\n",
    "def extract_cqa(text):\n",
    "    raw = text['output']\n",
    "    match = re.search(r'\\{.*\\}', raw, re.DOTALL)\n",
    "    if not match:\n",
    "        return extract_all_cqa(text)\n",
    "    json_str = match.group()\n",
    "    json_str = json_str.replace('{{', '{').replace('}}', '}')\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        qa_pairs = data.get(\"question_answer_pairs\", [])\n",
    "        qa_pairs = [{\"question\": pair.get(\"question\", \"\").strip(), \"answer\": pair.get(\"answer\", \"\").strip()} for pair in qa_pairs if isinstance(pair, dict)]\n",
    "        return {\"qa\": qa_pairs, \"qa_num\": len(qa_pairs)}\n",
    "    except json.JSONDecodeError:\n",
    "        return extract_all_cqa(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194991f",
   "metadata": {},
   "source": [
    "## CSQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"csqa\"\n",
    "stage = 0\n",
    "print(f\"Processing {data_type} data for stage {stage}\")\n",
    "base_path = f\"/scratch/azureml/cr/j/a29d46b9ba574a9abc8a7dea98bdf971/cap/data-capability/wd/INPUT_asdf/CurLL_data/stages/stage{stage}/{data_type}\"\n",
    "df = load_all_files(base_path)\n",
    "cdata_path = f\"Pavankalyan/stage{stage}_context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86792ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(\n",
    "    extract_details_csqa,\n",
    "    remove_columns=df.column_names,\n",
    "    desc=\"Extracting details from CSQA data\",\n",
    "    num_proc=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(\n",
    "    extract_csqa,\n",
    "    desc=\"Extracting question-answer pairs from CSQA data\",\n",
    "    num_proc=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df.filter(lambda x: x['qa_num'] < 1, desc=\"Filtering bad samples\", num_proc=60)\n",
    "df_good = df.filter(lambda x: x['qa_num'] >= 1, desc=\"Filtering good samples\", num_proc=60)\n",
    "len(df_bad), len(df_good)\n",
    "df_good = df_good.select_columns(['context', 'qa'])\n",
    "cdata = load_dataset(cdata_path, split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip().lower())\n",
    "\n",
    "print(\"Building mapping from df_good...\")\n",
    "context_to_qa = {}\n",
    "for ctx, qa in tqdm(zip(df_good['context'], df_good['qa'])):\n",
    "    cleaned = clean_text(ctx)\n",
    "    if cleaned not in context_to_qa:  # only first match\n",
    "        context_to_qa[cleaned] = qa\n",
    "        \n",
    "def add_qa_column(batch):\n",
    "    batch['csqa'] = [\n",
    "        context_to_qa.get(clean_text(output), None)\n",
    "        for output in batch['output']\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "print(\"Mapping QA into cdata...\")\n",
    "cdata_augmented = cdata.map(\n",
    "    add_qa_column,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=80,  # adjust based on your CPU\n",
    "    desc=\"Joining datasets\"\n",
    ")\n",
    "\n",
    "cdata_no_qa = cdata_augmented.filter(lambda x: x['csqa'] is None, num_proc=80)\n",
    "cdata_final = cdata_augmented.filter(lambda x: x['csqa'] is not None, num_proc=80)\n",
    "cdata_final.push_to_hub(\"Pavankalyan/stage0_csqa\", split=\"train\", token=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f07df5",
   "metadata": {},
   "source": [
    "## CQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"cqa\"\n",
    "stage = 0\n",
    "print(f\"Processing {data_type} data for stage {stage}\")\n",
    "base_path = f\"/scratch/azureml/cr/j/a29d46b9ba574a9abc8a7dea98bdf971/cap/data-capability/wd/INPUT_asdf/CurLL_data/stages/stage{stage}/{data_type}\"\n",
    "df = load_all_files(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(\n",
    "    extract_details_cqa,\n",
    "    remove_columns=df.column_names,\n",
    "    desc=\"Extracting details from CSQA data\",\n",
    "    num_proc=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b378e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(\n",
    "    extract_cqa,\n",
    "    desc=\"Extracting question-answer pairs from CSQA data\",\n",
    "    num_proc=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c302b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df.filter(lambda x: x['qa_num'] < 1, desc=\"Filtering bad samples\", num_proc=60)\n",
    "df_good = df.filter(lambda x: x['qa_num'] >= 1, desc=\"Filtering good samples\", num_proc=60)\n",
    "df_good = df_good.select_columns(['context', 'qa'])\n",
    "cdata_path = f\"Pavankalyan/stage{stage}_csqa\"\n",
    "cdata = load_dataset(cdata_path, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip().lower())\n",
    "print(\"Building mapping from df_good...\")\n",
    "context_to_qa = {}\n",
    "for ctx, qa in tqdm(zip(df_good['context'], df_good['qa'])):\n",
    "    cleaned = clean_text(ctx)\n",
    "    if cleaned not in context_to_qa:  # only first match\n",
    "        context_to_qa[cleaned] = qa\n",
    "        \n",
    "        \n",
    "def add_qa_column(batch):\n",
    "    batch['cqa'] = [\n",
    "        context_to_qa.get(clean_text(output), None)\n",
    "        for output in batch['output']\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping QA into cdata...\")\n",
    "cdata_augmented = cdata.map(\n",
    "    add_qa_column,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=80,  # adjust based on your CPU\n",
    "    desc=\"Joining datasets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata_no_qa = cdata_augmented.filter(lambda x: x['cqa'] is None, num_proc=80)\n",
    "cdata_final = cdata_augmented.filter(lambda x: x['cqa'] is not None, num_proc=80)\n",
    "cdata_final.push_to_hub(\"Pavankalyan/stage0_c_all\", split=\"train\", token=\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
