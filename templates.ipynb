{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import json\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03417e9",
   "metadata": {},
   "source": [
    "## Seed for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de880630",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"indicator_graph_edges_weighted.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_skill = {}\n",
    "# Iterate over each node to count outgoing connections by last stage label\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "\n",
    "    if node_stage not in stage_skill:\n",
    "        stage_skill[node_stage] = []\n",
    "\n",
    "    if node_skill not in stage_skill[node_stage]:\n",
    "        stage_skill[node_stage].append(node_skill)\n",
    "\n",
    "print(\"Stage and Skills:\")\n",
    "for stage, skills in stage_skill.items():\n",
    "    print(f\"Stage {stage}: {', '.join(skills)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9581b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_type_seed = []\n",
    "\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "    node_subskill = DG.nodes[node].get('subskill', None)\n",
    "    node_goal = DG.nodes[node].get('goal', None)\n",
    "    node_age_group = DG.nodes[node].get('age_group', None)\n",
    "    node_indicator = DG.nodes[node].get('label', None)\n",
    "    node_id = node\n",
    "\n",
    "    if node_stage is not None and node_skill is not None and node_subskill is not None and node_goal is not None and node_age_group is not None and node_indicator is not None:\n",
    "        text_type_seed.append({\n",
    "            \"indicator\": node_indicator,\n",
    "            \"age_group\": node_age_group,\n",
    "            \"skill\": node_skill,\n",
    "            \"subskill\": node_subskill,\n",
    "            \"goal\": node_goal,\n",
    "            \"stage\": node_stage,\n",
    "            \"id\" : node_id\n",
    "        })\n",
    "\n",
    "print(len(DG.nodes())), print(len(text_type_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6abb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/text_types_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(text_type_seed, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ffd76",
   "metadata": {},
   "source": [
    "## Prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda65d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_response_prompt = {\n",
    "  \"system\": \"You are an expert in child development, skill acquisition, curriculum design, and language model pretraining. Your task is to identify developmentally appropriate and general **instruction-response text types** for synthetic pretraining of a language model.\\n\\nEach input includes:\\n- indicator: a natural language description of the learning objective or task\\n- age_group: developmental age (e.g., 0–5, 5–11, 11–14)\\n- skill: broad academic or developmental domain (e.g., Mathematics, English, Scientific Reasoning)\\n- subskill: a specific subdomain or area of focus (e.g., Listening, Measurement, Problem-solving)\\n- goal: the purpose or nature of the learning (e.g., Application, Reflection, Evaluation)\\n- stage: the curriculum stage (0 to 9, loosely corresponding to increasing age and complexity)\\n\\nInstructions:\\nReturn a list of **general instruction-response style text types** that:\\n- Are suitable for the learner's developmental stage\\n- Can be used in instruction tuning and task-based language modeling\\n- Involve a clearly defined instruction format that can be applied across many topics\\n- Are defined at a high level of abstraction (e.g., \\\"explain why X occurs\\\", \\\"compare and contrast X and Y\\\")\\n\\n**CRITICALLY IMPORTANT**:\\n- Provide abstract instruction formats, NOT specific prompts or questions\\n- Text types should be 2-5 words describing a general instruction format\\n- Each text type should be usable with ANY topic relevant to the age/skill combination\\n\\n**Examples of appropriate instruction-response text types**:\\n- \\\"Compare and contrast analysis\\\"\\n- \\\"Explain why reasoning\\\"\\n- \\\"Step-by-step instruction\\\"\\n- \\\"Open-ended reflection prompt\\\"\\n\\n**Examples of inappropriate text types** (too specific):\\n- \\\"Explain why plants need water\\\"\\n- \\\"Compare dogs and cats\\\"\\n- \\\"Describe your favorite toy\\\"\\n\\nOutput Format:\\nReturn your result as a JSON object with the following structure:\\n\\n```json\\n{{\\n  \\\"text_types\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n}}\\n```\\n\\nEnsure the list is:\\n- 15–20 items long\\n- Abstract enough to work across many topics\\n- Varied across explanation, reasoning, reflection, comparison, instruction, imagination\\n- Appropriate in complexity for the given age group and learning goal\\n\\nOnly output the JSON object.\",\n",
    "  \"user\": \"Given the following information about a learning objective, return a list of general, reusable instruction-response text formats that can serve as templates for synthetic training data:\\n\\n- indicator: {indicator}\\n- age_group: {age_group}\\n- skill: {skill}\\n- subskill: {subskill}\\n- goal: {goal}\\n- stage: {stage}\\n\\nIMPORTANT: Provide ABSTRACT INSTRUCTION FORMATS (2-5 words each), not specific questions or prompts.\\n\\nExamples of good instruction formats:\\n- \\\"Compare and contrast analysis\\\"\\n- \\\"Explain why reasoning\\\"\\n- \\\"Problem-solving walkthrough\\\"\\n- \\\"Open-ended reflection prompt\\\"\\n\\nExamples of unsuitable formats (too specific):\\n- \\\"Explain why plants need water\\\"\\n- \\\"Compare dogs and cats\\\"\\n- \\\"Solve this math problem\\\"\\n\\nEnsure your list contains:\\n- 15 to 20 developmentally appropriate instruction formats\\n- General templates that can be combined with ANY relevant topic\\n- Varied instruction types that address different cognitive processes\\n\\nReturn only a JSON object in the following format:\\n\\n```json\\n{{\\n  \\\"text_types\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n}}\\n```\"\n",
    "}\n",
    "print(instruction_response_prompt['system'])\n",
    "print(\"______________________\")\n",
    "print(instruction_response_prompt['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_only_prompt = {\n",
    "  \"system\": \"You are an expert in child development, skill acquisition, curriculum design, and language model pretraining. Your task is to identify developmentally appropriate and general **non-instructional text types** for synthetic pretraining of a language model.\\n\\nEach input includes:\\n- indicator: a natural language description of the learning objective or task\\n- age_group: developmental age (e.g., 0–5, 5–11, 11–14)\\n- skill: broad academic or developmental domain (e.g., Mathematics, English, Scientific Reasoning)\\n- subskill: a specific subdomain or area of focus (e.g., Listening, Measurement, Problem-solving)\\n- goal: the purpose or nature of the learning (e.g., Application, Reflection, Evaluation)\\n- stage: the curriculum stage (0 to 9, loosely corresponding to increasing age and complexity)\\n\\nInstructions:\\nReturn a list of **general non-instructional text types** that:\\n- Are suitable for the learner's developmental stage\\n- Reflect naturalistic or structured formats that don't rely on explicit instruction–response pairs\\n- Can be used as abstract templates to generate content across many topics\\n- Are defined at a high level of abstraction (e.g., \\\"peer dialogue\\\", \\\"narrative description\\\", \\\"cause-effect explanation\\\")\\n\\n**CRITICALLY IMPORTANT**:\\n- Provide format categories, NOT specific content or scenarios\\n- Text types should be 2-5 words that describe a general format, not complete sentences\\n- Each text type should be usable with ANY topic relevant to the age/skill combination\\n\\n**Examples of appropriate non-instructional text types**:\\n- \\\"Narrative story with characters\\\"\\n- \\\"Peer conversation transcript\\\"\\n- \\\"Process description passage\\\"\\n- \\\"Personal reflection monologue\\\"\\n\\n**Examples of inappropriate text types** (too specific):\\n- \\\"Story about a child going to the zoo\\\"\\n- \\\"Conversation between friends about toys\\\"\\n- \\\"Description of a butterfly's life cycle\\\"\\n\\nOutput Format:\\nReturn your result as a JSON object with the following structure:\\n\\n```json\\n{{\\n  \\\"text_types\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n}}\\n```\\n\\nEnsure the list is:\\n- 15–20 items long\\n- Abstract enough to work across many topics\\n- Varied across narration, description, interaction, emotion, reasoning\\n- Appropriate in complexity for the given age group and learning goal\\n\\nOnly output the JSON object.\",\n",
    "  \"user\": \"Given the following information about a learning objective, return a list of general, reusable non-instructional text formats that can serve as templates for synthetic training data:\\n\\n- indicator: {indicator}\\n- age_group: {age_group}\\n- skill: {skill}\\n- subskill: {subskill}\\n- goal: {goal}\\n- stage: {stage}\\n\\nIMPORTANT: Provide ABSTRACT FORMAT CATEGORIES (2-5 words each), not specific content or scenarios.\\n\\nExamples of good non-instructional formats:\\n- \\\"Peer dialogue transcript\\\"\\n- \\\"Sequential process description\\\"\\n- \\\"Character-driven narrative\\\"\\n- \\\"Emotional experience monologue\\\"\\n\\nExamples of unsuitable formats (too specific):\\n- \\\"Conversation between friends about toys\\\"\\n- \\\"Description of a butterfly's life cycle\\\"\\n- \\\"Story about going to the beach\\\"\\n\\nEnsure your list contains:\\n- 15 to 20 developmentally appropriate text formats\\n- General templates that can be combined with ANY relevant topic\\n- Varied format types that don't rely on explicit instruction-response pairs\\n\\nReturn only a JSON object in the following format:\\n\\n```json\\n{{\\n  \\\"text_types\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n}}\\n```\"\n",
    "}\n",
    "print(context_only_prompt['system'])\n",
    "print(\"______________________\")\n",
    "print(context_only_prompt['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./text_type_prompt4.1.json\", \"w\") as f:\n",
    "    json.dump(instruction_response_prompt, f, indent=4)\n",
    "\n",
    "with open(\"./text_type_prompt4.2.json\", \"w\") as f:\n",
    "    json.dump(context_only_prompt, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c2bcd",
   "metadata": {},
   "source": [
    "## Verification and correction of generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_ins_text_prompt = {\"system\": \"You are an expert in child development, curriculum design, skill acquisition, and language model instruction tuning. Your task is to evaluate whether a proposed **instruction-response text type** is appropriate for use in synthetic pretraining and instruction tuning for a given learning task and learner profile.\\n\\nEach evaluation includes:\\n- text_type: the proposed abstract instruction-response format (e.g., \\\"Explain why reasoning\\\")\\n- indicator: a natural language description of the learning objective or task\\n- age_group: developmental age range (e.g., 5–11)\\n- skill: broad academic or developmental domain (e.g., Mathematics)\\n- subskill: specific area of focus (e.g., Measurement)\\n- goal: purpose or nature of learning (e.g., Application, Reflection)\\n- stage: curriculum stage (0–9, with 0 being youngest learners)\\n\\nYour job is to decide:\\n- Is this text_type a good abstract template for this task and learner profile?\\n\\nOutput your judgment in the following JSON format:\\n\\n```json\\n{{\\n  \\\"is_valid\\\": \\\"YES\\\" or \\\"NO\\\",\\n  \\\"justification\\\": \\\"A concise explanation (1-2 sentences) of why this text type is or isn't appropriate for this indicator and learner profile.\\\"\\n}}\\n```\\n\\nEvaluation Criteria:\\n- The text_type should be **abstract and generalizable**, not topic-specific or overly concrete.\\n- It should be **developmentally appropriate** for the given age_group and stage.\\n- It should align with the **learning goal** (e.g., reflection, analysis, reasoning, application).\\n- It should be usable across a wide range of topics for the given skill/subskill.\\n- It should be suitable for **instruction tuning** or **task-based language modeling** in a general-purpose educational language model.\\n\\nExamples of valid text_types: \\\"Explain why reasoning\\\", \\\"Compare and contrast analysis\\\", \\\"Open-ended reflection prompt\\\", \\\"Step-by-step instruction\\\"\\nExamples of invalid text_types: \\\"Describe your favorite animal\\\", \\\"Explain the water cycle\\\", \\\"Name three triangle types\\\"\",\n",
    "                       \"user\": \"Evaluate if this text type is appropriate for instruction tuning:\\n\\ntext_type: \\\"{text_type}\\\"\\nindicator: \\\"{indicator}\\\"\\nage_group: \\\"{age_group}\\\"\\nskill: \\\"{skill}\\\"\\nsubskill: \\\"{subskill}\\\"\\ngoal: \\\"{goal}\\\"\\nstage: {stage}\\n\\nReturn only a JSON object:\\n\\n```json\\n{{\\n  \\\"is_valid\\\": \\\"YES\\\" or \\\"NO\\\",\\n  \\\"justification\\\": \\\"A brief explanation of why.\\\"\\n}}\\n```\"}\n",
    "\n",
    "ver_nins_text_prompt = {\"system\": \"You are an expert in child development, curriculum design, skill acquisition, and language model instruction tuning. Your task is to evaluate whether a proposed **non-instructional text type** is appropriate for use in synthetic pretraining of a language model for a given learning task and learner profile.\\n\\nEach evaluation includes:\\n- text_type: the proposed abstract non-instructional format (e.g., \\\"Narrative story with characters\\\")\\n- indicator: a natural language description of the learning objective or task\\n- age_group: developmental age range (e.g., 5–11)\\n- skill: broad academic or developmental domain (e.g., Mathematics)\\n- subskill: specific area of focus (e.g., Measurement)\\n- goal: purpose or nature of learning (e.g., Application, Reflection)\\n- stage: curriculum stage (0–9, with 0 being youngest learners)\\n\\nYour job is to decide:\\n- Is this text_type a good abstract template for this task and learner profile?\\n\\nOutput your judgment in the following JSON format:\\n\\n```json\\n{{\\n  \\\"is_valid\\\": \\\"YES\\\" or \\\"NO\\\",\\n  \\\"justification\\\": \\\"A concise explanation (1-2 sentences) of why this text type is or isn't appropriate for this indicator and learner profile.\\\"\\n}}\\n```\\n\\nEvaluation Criteria:\\n- The text_type should be **abstract and generalizable**, not topic-specific or overly concrete.\\n- It should be **developmentally appropriate** for the given age_group and stage.\\n- It should align with the **learning goal** (e.g., reflection, analysis, reasoning, application).\\n- It should be usable across a wide range of topics for the given skill/subskill.\\n- It should reflect naturalistic or structured formats that don't rely on explicit instruction-response pairs.\\n- It should be suitable for **synthetic pretraining** of a general-purpose educational language model.\\n\\nExamples of valid text_types: \\\"Narrative story with characters\\\", \\\"Peer conversation transcript\\\", \\\"Process description passage\\\", \\\"Personal reflection monologue\\\"\\nExamples of invalid text_types: \\\"Story about a child going to the zoo\\\", \\\"Conversation between friends about toys\\\", \\\"Description of a butterfly's life cycle\\\"\",\n",
    "                        \"user\": \"Evaluate if this text type is appropriate for synthetic pretraining:\\n\\ntext_type: \\\"{text_type}\\\"\\nindicator: \\\"{indicator}\\\"\\nage_group: \\\"{age_group}\\\"\\nskill: \\\"{skill}\\\"\\nsubskill: \\\"{subskill}\\\"\\ngoal: \\\"{goal}\\\"\\nstage: {stage}\\n\\nReturn only a JSON object:\\n\\n```json\\n{{\\n  \\\"is_valid\\\": \\\"YES\\\" or \\\"NO\\\",\\n  \\\"justification\\\": \\\"A brief explanation of why.\\\"\\n}}\\n```\"}\n",
    "\n",
    "#save the prompts\n",
    "with open(\"./ver_ins_text_prompt.json\", \"w\") as f:\n",
    "    json.dump(ver_ins_text_prompt, f, indent=4)\n",
    "\n",
    "with open(\"./ver_nins_text_prompt.json\", \"w\") as f:\n",
    "    json.dump(ver_nins_text_prompt, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60e0af",
   "metadata": {},
   "source": [
    "### Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ver_ins_text_raw.jsonl\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "all_dicts = [o for o in data if isinstance(o['output'], dict) and o['output']['is_valid'] in [\"YES\", \"NO\"]]\n",
    "non_dicts = [o for o in data if not isinstance(o['output'], dict) or o['output']['is_valid'] not in [\"YES\", \"NO\"]]\n",
    "print(len(all_dicts)), print(len(non_dicts))\n",
    "\n",
    "non_dicts[0]['output'] = {\"is_valid\": \"NO\",\n",
    " \"justification\": \"While prompting for continuation (\\\"What happened next?\\\") can be useful, this text type is too open-ended and doesn\\'t directly address the sensitive and complex task of explaining the difference between a slave and a free person, especially for this age group. It lacks the necessary framing for a nuanced and historically accurate response.\"}\n",
    "ins_dicts = all_dicts + non_dicts\n",
    "\n",
    "answers = {}\n",
    "for i in ins_dicts:\n",
    "    answers[i['output']['is_valid']] = answers.get(i['output']['is_valid'],0)\n",
    "    answers[i['output']['is_valid']] += 1\n",
    "print(answers)\n",
    "\n",
    "ins_dict = {}\n",
    "for i in ins_dicts:\n",
    "    ins_dict[i['stage']] = ins_dict.get(i['stage'],{})\n",
    "    ins_dict[i['stage']][i['skill']] = ins_dict[i['stage']].get(i['skill'], {})\n",
    "    ins_dict[i['stage']][i['skill']][i['output']['is_valid']] = ins_dict[i['stage']][i['skill']].get(i['output']['is_valid'], 0)\n",
    "    ins_dict[i['stage']][i['skill']][i['output']['is_valid']] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41890b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ver_nins_text_raw.jsonl\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "all_dicts = [o for o in data if isinstance(o['output'], dict) and o['output']['is_valid'] in [\"YES\", \"NO\"]]\n",
    "non_dicts = [o for o in data if not isinstance(o['output'], dict) or o['output']['is_valid'] not in [\"YES\", \"NO\"]]\n",
    "print(len(all_dicts)), print(len(non_dicts))\n",
    "\n",
    "non_dicts[0]['output'] = {\"is_valid\": \"YES\",\n",
    " \"justification\": \"Recipe instructions naturally contain imperative verbs and can be easily adapted to include direct speech (e.g., \\'Mom said, \\\"Add the flour now!\\\"\\'), providing a context for experimenting with verb forms appropriate for this age group and writing goal.\"}\n",
    "nins_dicts = non_dicts + all_dicts\n",
    "\n",
    "answers = {}\n",
    "for i in nins_dicts:\n",
    "    answers[i['output']['is_valid']] = answers.get(i['output']['is_valid'],0)\n",
    "    answers[i['output']['is_valid']] += 1\n",
    "print(answers)\n",
    "\n",
    "nins_dict = {}\n",
    "for i in nins_dicts:\n",
    "    nins_dict[i['stage']] = nins_dict.get(i['stage'],{})\n",
    "    nins_dict[i['stage']][i['skill']] = nins_dict[i['stage']].get(i['skill'], {})\n",
    "    nins_dict[i['stage']][i['skill']][i['output']['is_valid']] = nins_dict[i['stage']][i['skill']].get(i['output']['is_valid'], 0)\n",
    "    nins_dict[i['stage']][i['skill']][i['output']['is_valid']] +=1\n",
    "\n",
    "ins_data = {}\n",
    "for i in ins_dicts:\n",
    "    if i['output']['is_valid'] == 'YES':\n",
    "        ins_data[i['id']] = ins_data.get(i['id'], [])\n",
    "        ins_data[i['id']].append(i['text_type'])\n",
    "\n",
    "nins_data = {}\n",
    "for i in nins_dicts:\n",
    "    if i['output']['is_valid'] == 'YES':\n",
    "        nins_data[i['id']] = nins_data.get(i['id'], [])\n",
    "        nins_data[i['id']].append(i['text_type'])\n",
    "\n",
    "ins_d = {}\n",
    "for i in ins_dicts:\n",
    "    ins_d[i['id']] = ins_d.get(i['id'], {})\n",
    "    ins_d[i['id']][i['output']['is_valid']] = ins_d[i['id']].get(i['output']['is_valid'], 0)\n",
    "    ins_d[i['id']][i['output']['is_valid']] += 1\n",
    "nins_d = {}\n",
    "for i in nins_dicts:\n",
    "    nins_d[i['id']] = nins_d.get(i['id'], {})\n",
    "    nins_d[i['id']][i['output']['is_valid']] = nins_d[i['id']].get(i['output']['is_valid'], 0)\n",
    "    nins_d[i['id']][i['output']['is_valid']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb50c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ins_samples = {\"zero\": [], \"less_10\": [], \"less_15\": []}\n",
    "good_ins_samples = []\n",
    "for j in ins_d:\n",
    "    if 'YES' not in ins_d[j].keys():\n",
    "        bad_ins_samples[\"zero\"].append(j)\n",
    "    elif ins_d[j]['YES'] < 10:\n",
    "        bad_ins_samples[\"less_10\"].append(j)\n",
    "    elif ins_d[j]['YES'] < 15:\n",
    "        bad_ins_samples[\"less_15\"].append(j)\n",
    "    else:\n",
    "        good_ins_samples.append(j)\n",
    "\n",
    "bad_c_samples = {\"zero\": [], \"less_10\": [], \"less_15\": []}\n",
    "good_c_samples = []\n",
    "for j in nins_d:\n",
    "    if 'YES' not in nins_d[j].keys():\n",
    "        bad_c_samples[\"zero\"].append(j)\n",
    "    elif nins_d[j]['YES'] < 10:\n",
    "        bad_c_samples[\"less_10\"].append(j)\n",
    "    elif nins_d[j]['YES'] < 15:\n",
    "        bad_c_samples[\"less_15\"].append(j)\n",
    "    else:\n",
    "        good_c_samples.append(j)\n",
    "print(\"bad ins samples: \", len(bad_ins_samples[\"less_15\"]))\n",
    "print(\"bad nins samples: \", len(bad_c_samples[\"less_15\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39979ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the bad samples\n",
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/bad_ins_samples.json\", \"w\") as f:\n",
    "    json.dump(bad_ins_samples, f, indent=4)\n",
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/bad_c_samples.json\", \"w\") as f:\n",
    "    json.dump(bad_c_samples, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13444170",
   "metadata": {},
   "source": [
    "## Add good templates to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e99f5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./indicator_graph_edges_weighted.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7160887",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in DG.nodes():\n",
    "    if node in good_ins_samples:\n",
    "        DG.nodes[node]['ins_templates'] = ins_data[node]\n",
    "    if node in good_c_samples:\n",
    "        DG.nodes[node]['context_templates'] = nins_data[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./graph_with_good_templates.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DG, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ae80b",
   "metadata": {},
   "source": [
    "## Correct bad templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b51e35e",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76664eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./indicator_graph_edges_weighted.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)\n",
    "\n",
    "with open(\"./bad_ins_samples.json\", \"r\") as f:\n",
    "    bad_ins = json.load(f)\n",
    "\n",
    "with open(\"./bad_c_samples.json\", \"r\") as f:\n",
    "    bad_c = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ins = bad_ins['less_15'] + bad_ins['less_10'] + bad_ins['zero']\n",
    "bad_c = bad_c['less_15'] + bad_c['less_10'] + bad_c['zero']\n",
    "\n",
    "bad_ins_seed = []\n",
    "bad_c_seed = []\n",
    "\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "    node_subskill = DG.nodes[node].get('subskill', None)\n",
    "    node_goal = DG.nodes[node].get('goal', None)\n",
    "    node_age_group = DG.nodes[node].get('age_group', None)\n",
    "    node_indicator = DG.nodes[node].get('label', None)\n",
    "    node_id = node\n",
    "\n",
    "    if node in bad_ins:\n",
    "        bad_ins_seed.append({\n",
    "            \"indicator\": node_indicator,\n",
    "            \"age_group\": node_age_group,\n",
    "            \"skill\": node_skill,\n",
    "            \"subskill\": node_subskill,\n",
    "            \"goal\": node_goal,\n",
    "            \"stage\": node_stage,\n",
    "            \"id\" : node_id\n",
    "        })\n",
    "\n",
    "    if node in bad_c:\n",
    "        bad_c_seed.append({\n",
    "            \"indicator\": node_indicator,\n",
    "            \"age_group\": node_age_group,\n",
    "            \"skill\": node_skill,\n",
    "            \"subskill\": node_subskill,\n",
    "            \"goal\": node_goal,\n",
    "            \"stage\": node_stage,\n",
    "            \"id\" : node_id\n",
    "        })\n",
    "        \n",
    "with open(\"./bad_ins_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(bad_ins_seed, f, indent=4)\n",
    "\n",
    "with open(\"./bad_c_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(bad_c_seed, f, indent=4)\n",
    "    \n",
    "with open(\"./text_type_prompt4.1.json\", \"r\") as f:\n",
    "    bad_ins_prompt = json.load(f)\n",
    "\n",
    "with open(\"./text_type_prompt4.2.json\", \"r\") as f:\n",
    "    bad_c_prompt = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a80794",
   "metadata": {},
   "source": [
    "### Post-processing generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bad_ins_raw.jsonl\", \"r\") as f:\n",
    "    bad_ins_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ba4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ins_all_dicts = [o for o in bad_ins_data if isinstance(o['output'], dict) and isinstance(o['output']['text_types'], list)]\n",
    "bad_ins_non_dicts = [o for o in bad_ins_data if not isinstance(o['output'], dict) or not isinstance(o['output']['text_types'], list)]\n",
    "print(len(bad_ins_all_dicts)), print(len(bad_ins_non_dicts))\n",
    "\n",
    "with open(\"./bad_c_raw.jsonl\", \"r\") as f:\n",
    "    bad_c_data = json.load(f)\n",
    "\n",
    "bad_c_all_dicts = [o for o in bad_c_data if isinstance(o['output'], dict) and isinstance(o['output']['text_types'], list)]\n",
    "bad_c_non_dicts = [o for o in bad_c_data if not isinstance(o['output'], dict) or not isinstance(o['output']['text_types'], list)]\n",
    "print(len(bad_c_all_dicts)), print(len(bad_c_non_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f018eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./indicator_graph_edges_weighted.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)\n",
    "\n",
    "ver_bad_ins_seed = []\n",
    "ver_bad_c_seed = []\n",
    "\n",
    "for node_data in bad_c_all_dicts:\n",
    "    node = node_data['id']\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "    node_subskill = DG.nodes[node].get('subskill', None)\n",
    "    node_goal = DG.nodes[node].get('goal', None)\n",
    "    node_age_group = DG.nodes[node].get('age_group', None)\n",
    "    node_indicator = DG.nodes[node].get('label', None)\n",
    "    node_id = node\n",
    "    tt = node_data['output']['text_types']\n",
    "    for t in tt:\n",
    "        ver_bad_c_seed.append({\n",
    "            \"indicator\": node_indicator,\n",
    "            \"age_group\": node_age_group,\n",
    "            \"skill\": node_skill,\n",
    "            \"subskill\": node_subskill,\n",
    "            \"goal\": node_goal,\n",
    "            \"stage\": node_stage,\n",
    "            \"text_type\" : t,\n",
    "            \"id\" : node_id\n",
    "        })\n",
    "\n",
    "for node_data in bad_ins_all_dicts:\n",
    "    node = node_data['id']\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "    node_subskill = DG.nodes[node].get('subskill', None)\n",
    "    node_goal = DG.nodes[node].get('goal', None)\n",
    "    node_age_group = DG.nodes[node].get('age_group', None)\n",
    "    node_indicator = DG.nodes[node].get('label', None)\n",
    "    node_id = node\n",
    "    tt = node_data['output']['text_types']\n",
    "    for t in tt:\n",
    "        ver_bad_ins_seed.append({\n",
    "            \"indicator\": node_indicator,\n",
    "            \"age_group\": node_age_group,\n",
    "            \"skill\": node_skill,\n",
    "            \"subskill\": node_subskill,\n",
    "            \"goal\": node_goal,\n",
    "            \"stage\": node_stage,\n",
    "            \"text_type\" : t,\n",
    "            \"id\" : node_id\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ver_bad_c_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(ver_bad_c_seed, f, indent=4)\n",
    "\n",
    "with open(\"./ver_bad_ins_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(ver_bad_ins_seed, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ver_bad_ins_raw.jsonl\", \"r\") as f:\n",
    "    ver_bad_ins_data = json.load(f)\n",
    "\n",
    "with open(\"./ver_bad_c_raw.jsonl\", \"r\") as f:\n",
    "    ver_bad_c_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e171a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_bad_ins_all_dicts = [o for o in ver_bad_ins_data if isinstance(o['output'], dict) and o['output']['is_valid'] in [\"YES\", \"NO\"]]\n",
    "ver_bad_ins_non_dicts = [o for o in ver_bad_ins_data if not isinstance(o['output'], dict) or o['output']['is_valid'] not in [\"YES\", \"NO\"]]\n",
    "print(len(ver_bad_ins_all_dicts)), print(len(ver_bad_ins_non_dicts))\n",
    "ver_bad_c_all_dicts = [o for o in ver_bad_c_data if isinstance(o['output'], dict) and o['output']['is_valid'] in [\"YES\", \"NO\"]]\n",
    "ver_bad_c_non_dicts = [o for o in ver_bad_c_data if not isinstance(o['output'], dict) or o['output']['is_valid'] not in [\"YES\", \"NO\"]]\n",
    "print(len(ver_bad_c_all_dicts)), print(len(ver_bad_c_non_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01561d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_bad_ins_results = {}\n",
    "ver_bad_c_results = {}\n",
    "for i in ver_bad_c_all_dicts:\n",
    "    ver_bad_c_results[i['id']] = ver_bad_c_results.get(i['id'], {})\n",
    "    ver_bad_c_results[i['id']][i['output']['is_valid']] = ver_bad_c_results[i['id']].get(i['output']['is_valid'], [])\n",
    "    ver_bad_c_results[i['id']][i['output']['is_valid']].append(i['text_type'])\n",
    "for i in ver_bad_ins_all_dicts:\n",
    "    ver_bad_ins_results[i['id']] = ver_bad_ins_results.get(i['id'], {})\n",
    "    ver_bad_ins_results[i['id']][i['output']['is_valid']] = ver_bad_ins_results[i['id']].get(i['output']['is_valid'], [])\n",
    "    ver_bad_ins_results[i['id']][i['output']['is_valid']].append(i['text_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ae60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ver_bad_c_results:\n",
    "    if 'YES' in ver_bad_c_results[i].keys():\n",
    "        if len(ver_bad_c_results[i]['YES']) < 15:\n",
    "            #Sample from No text types until 15 length\n",
    "            while len(ver_bad_c_results[i]['YES']) < 15:\n",
    "                if len(ver_bad_c_results[i]['NO']) == 0:\n",
    "                    break\n",
    "                ver_bad_c_results[i]['YES'].append(ver_bad_c_results[i]['NO'].pop(0))\n",
    "    else:\n",
    "        ver_bad_c_results[i]['YES'] = []\n",
    "        while len(ver_bad_c_results[i]['YES']) < 15:\n",
    "            if len(ver_bad_c_results[i]['NO']) == 0:\n",
    "                break\n",
    "            ver_bad_c_results[i]['YES'].append(ver_bad_c_results[i]['NO'].pop(0))\n",
    "\n",
    "for i in ver_bad_ins_results:\n",
    "    if 'YES' in ver_bad_ins_results[i].keys():\n",
    "        if len(ver_bad_ins_results[i]['YES']) < 15:\n",
    "            #Sample from No text types until 15 length\n",
    "            while len(ver_bad_ins_results[i]['YES']) < 15:\n",
    "                if len(ver_bad_ins_results[i]['NO']) == 0:\n",
    "                    break\n",
    "                ver_bad_ins_results[i]['YES'].append(ver_bad_ins_results[i]['NO'].pop(0))\n",
    "    else:\n",
    "        ver_bad_ins_results[i]['YES'] = []\n",
    "        while len(ver_bad_ins_results[i]['YES']) < 15:\n",
    "            if len(ver_bad_ins_results[i]['NO']) == 0:\n",
    "                break\n",
    "            ver_bad_ins_results[i]['YES'].append(ver_bad_ins_results[i]['NO'].pop(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b0dca3",
   "metadata": {},
   "source": [
    "### Save the graph with templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc80c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./graph_with_good_templates.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a40a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ver_bad_ins_results:\n",
    "    DG.nodes[i]['ins_templates'] = ver_bad_ins_results[i]['YES']\n",
    "\n",
    "for i in ver_bad_c_results:\n",
    "    DG.nodes[i]['context_templates'] = ver_bad_c_results[i]['YES']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./graph_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DG, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
