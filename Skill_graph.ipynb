{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import json\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3aeb00",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86255d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the csv files, links in the README.md\n",
    "DG = nx.DiGraph()\n",
    "p1 = \"age_0_5.csv\"\n",
    "p2 = \"age_5_11.csv\"\n",
    "p3 = \"age_11_14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv(p1, encoding=\"utf-8\")\n",
    "dd.columns = dd.columns.str.strip()\n",
    "all_nan_rows = dd[dd.isna().all(axis=1)]\n",
    "dd.ffill(inplace=True)\n",
    "\n",
    "i=0\n",
    "df = dd\n",
    "for skill in df[\"Skills\"].unique():\n",
    "    skill_df = df[df[\"Skills\"] == skill]\n",
    "    for subskill in skill_df[\"Sub-skills\"].unique():\n",
    "        subskill_df = skill_df[skill_df[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_df[\"Goals\"].unique():\n",
    "            goal_df = subskill_df[subskill_df[\"Goals\"] == goal]\n",
    "            for stage in [\"stage-0\"]:\n",
    "                for indicator in goal_df[stage].unique():\n",
    "                    lab = [int(stage.split(\"-\")[1])]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"0-5\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "dd = pd.read_csv(p2, encoding=\"utf-8\")\n",
    "dd.columns = dd.columns.str.strip()\n",
    "all_nan_rows = dd[dd.isna().all(axis=1)]\n",
    "dd.ffill(inplace=True)\n",
    "\n",
    "df = dd.iloc[:298, :]\n",
    "for skill in df[\"Skills\"].unique():\n",
    "    skill_df = df[df[\"Skills\"] == skill]\n",
    "    for subskill in skill_df[\"Sub-skills\"].unique():\n",
    "        subskill_df = skill_df[skill_df[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_df[\"Goals\"].unique():\n",
    "            goal_df = subskill_df[subskill_df[\"Goals\"] == goal]\n",
    "            for stage in [\"stage-1\", \"stage-2\", \"stage-3\", \"stage-4\", \"stage-5\", \"stage-6\"]:\n",
    "                for indicator in goal_df[stage].unique():\n",
    "                    lab = [int(stage.split(\"-\")[1])]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "ds = dd.iloc[298:381, :]\n",
    "for skill in ds[\"Skills\"].unique():\n",
    "    skill_ds = ds[ds[\"Skills\"] == skill]\n",
    "    for subskill in skill_ds[\"Sub-skills\"].unique():\n",
    "        subskill_ds = skill_ds[skill_ds[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_ds[\"Goals\"].unique():\n",
    "            goal_ds = subskill_ds[subskill_ds[\"Goals\"] == goal]\n",
    "            for stage in [\"stage-1\", \"stage-4\"]:\n",
    "                for indicator in goal_ds[stage].unique():\n",
    "                    if stage == \"stage-1\":\n",
    "                        lab = [3]\n",
    "                    else:\n",
    "                        lab = [6]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "dm = dd.iloc[381:400, :]\n",
    "for skill in dm[\"Skills\"].unique():\n",
    "    skill_dm = dm[dm[\"Skills\"] == skill]\n",
    "    for subskill in skill_dm[\"Sub-skills\"].unique():\n",
    "        subskill_dm = skill_dm[skill_dm[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_dm[\"Goals\"].unique():  \n",
    "            goal_dm = subskill_dm[subskill_dm[\"Goals\"] == goal]\n",
    "            for stage in [\"stage-1\", \"stage-2\", \"stage-3\", \"stage-5\"]:\n",
    "                for indicator in goal_dm[stage].unique():\n",
    "                    if stage == \"stage-5\":\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=6, \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    elif stage == \"stage-3\":\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=4, \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    else:\n",
    "                        lab = [int(stage.split(\"-\")[1])]\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "dn = dd.iloc[400:, :]\n",
    "for skill in dn[\"Skills\"].unique():\n",
    "    skill_dn = dn[dn[\"Skills\"] == skill]\n",
    "    for subskill in skill_dn[\"Sub-skills\"].unique():\n",
    "        subskill_dn = skill_dn[skill_dn[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_dn[\"Goals\"].unique():\n",
    "            goal_dn = subskill_dn[subskill_dn[\"Goals\"] == goal]\n",
    "            for stage in [\"stage-1\", \"stage-2\", \"stage-3\", \"stage-4\", \"stage-5\", \"stage-6\"]:\n",
    "                for indicator in goal_dn[stage].unique():\n",
    "                    lab = [int(stage.split(\"-\")[1])]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"5-11\", skill=skill,\n",
    "                    subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                    modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                    embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "dd = pd.read_csv(p3, encoding=\"utf-8\")\n",
    "dd.columns = dd.columns.str.strip()\n",
    "all_nan_rows = dd[dd.isna().all(axis=1)]\n",
    "dd.ffill(inplace=True)\n",
    "\n",
    "df = dd.iloc[:220,:]\n",
    "for skill in df[\"Skills\"].unique():\n",
    "    skill_df = df[df[\"Skills\"] == skill]\n",
    "    for subskill in skill_df[\"Sub-skills\"].unique():\n",
    "        subskill_df = skill_df[skill_df[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_df[\"Goal\"].unique():\n",
    "            goal_df = subskill_df[subskill_df[\"Goal\"] == goal]\n",
    "            for stage in [\"Stage-7\", \"Stage-8\", \"Stage-9\"]:\n",
    "                for indicator in goal_df[stage].unique():\n",
    "                    lab = [int(stage.split(\"-\")[1])]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"11-14\", skill=skill,\n",
    "                    subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                    modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                    embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "ds = dd.iloc[220:239,:]\n",
    "for skill in ds[\"Skills\"].unique():\n",
    "    skill_ds = ds[ds[\"Skills\"] == skill]\n",
    "    for subskill in skill_ds[\"Sub-skills\"].unique():\n",
    "        subskill_ds = skill_ds[skill_ds[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_ds[\"Goal\"].unique():\n",
    "            goal_ds = subskill_ds[subskill_ds[\"Goal\"] == goal]\n",
    "            for stage in [\"Stage-7\", \"Stage-9\"]:\n",
    "                for indicator in goal_ds[stage].unique():\n",
    "                    if stage == \"Stage-7\":\n",
    "                        lab = [7,8]\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"11-14\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    else:\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"11-14\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=9, \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "ds = dd.iloc[239:320,:]\n",
    "for skill in ds[\"Skills\"].unique():\n",
    "    skill_ds = ds[ds[\"Skills\"] == skill]\n",
    "    for subskill in skill_ds[\"Sub-skills\"].unique():\n",
    "        subskill_ds = skill_ds[skill_ds[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_ds[\"Goal\"].unique():\n",
    "            goal_ds = subskill_ds[subskill_ds[\"Goal\"] == goal]\n",
    "            for stage in [\"Stage-7\"]:\n",
    "                for indicator in goal_ds[stage].unique():\n",
    "                    if stage == \"Stage-7\":\n",
    "                        DG.add_node(f\"i{i}\", label=indicator, age_group=\"11-14\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=9, \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1\n",
    "\n",
    "df = dd.iloc[320:,:]\n",
    "for skill in df[\"Skills\"].unique():\n",
    "    skill_df = df[df[\"Skills\"] == skill]\n",
    "    for subskill in skill_df[\"Sub-skills\"].unique():\n",
    "        subskill_df = skill_df[skill_df[\"Sub-skills\"] == subskill]\n",
    "        for goal in subskill_df[\"Goal\"].unique():\n",
    "            goal_df = subskill_df[subskill_df[\"Goal\"] == goal]\n",
    "            for stage in [\"Stage-7\", \"Stage-8\", \"Stage-9\"]:\n",
    "                for indicator in goal_df[stage].unique():\n",
    "                    lab = [int(stage.split(\"-\")[1])]\n",
    "                    DG.add_node(f\"i{i}\", label=indicator, age_group=\"11-14\", skill=skill,\n",
    "                        subskill=subskill, goal=goal, stage=lab[-1], \n",
    "                        modality_textual=None, perspective=None, require_multimodal_context=None,\n",
    "                        embodied=None)\n",
    "                    i += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DG.nodes), len(DG.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47955d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in DG.nodes(data=True):\n",
    "    print(n)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph\n",
    "with open(\"indicator_graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DG, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e61d9a",
   "metadata": {},
   "source": [
    "## Adding edges to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c58a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph\n",
    "with open(\"indicator_graph.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1d27cb",
   "metadata": {},
   "source": [
    "### Prepare data for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457372f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the llm data for prompting\n",
    "llm_data = [{\"id\":n, **d} for n, d in DG.nodes(data=True)]\n",
    "perm_llm_data = list(combinations(llm_data, 2))\n",
    "print(len(perm_llm_data))\n",
    "\n",
    "seed_data = []\n",
    "for i in range(len(perm_llm_data)):\n",
    "    seed_data.append({\n",
    "                \"id_1\": perm_llm_data[i][0][\"id\"],\n",
    "                \"id_2\": perm_llm_data[i][1][\"id\"],\n",
    "                \"label_1\": perm_llm_data[i][0][\"label\"],\n",
    "                \"label_2\": perm_llm_data[i][1][\"label\"],\n",
    "                \"age_group_1\": perm_llm_data[i][0][\"age_group\"],\n",
    "                \"age_group_2\": perm_llm_data[i][1][\"age_group\"],\n",
    "                \"skill_1\": perm_llm_data[i][0][\"skill\"],\n",
    "                \"skill_2\": perm_llm_data[i][1][\"skill\"],\n",
    "                \"subskill_1\": perm_llm_data[i][0][\"subskill\"],\n",
    "                \"subskill_2\": perm_llm_data[i][1][\"subskill\"],\n",
    "                \"goal_1\": perm_llm_data[i][0][\"goal\"],\n",
    "                \"goal_2\": perm_llm_data[i][1][\"goal\"],\n",
    "                \"stage_1\": perm_llm_data[i][0][\"stage\"],\n",
    "                \"stage_2\": perm_llm_data[i][1][\"stage\"],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = len(seed_data) // 10\n",
    "chunks = [seed_data[i:i + chunk_size] for i in range(0, len(seed_data), chunk_size)]\n",
    "# save each chunk to a separate file\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\"/seed/edge_seed_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30341a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = {\n",
    "    \"system\" : \"You are an expert in skill development and cognitive science. Your task is to analyze the relationship between two skill indicators and determine if there is a logical prerequisite dependency between them.\\n\\nEach skill indicator is given with:\\n- a_label and a_id\\n- b_label and b_id\\n\\nThese represent two distinct skill indicators. You must determine whether one is a prerequisite for the other.\\n\\nInstructions:\\n- A skill X is a prerequisite for skill Y if Y logically requires understanding or demonstrating X beforehand.\\n- Compare the meaning of a_label and b_label to determine if:\\n  - A depends on B → edge from b_id to a_id\\n  - B depends on A → edge from a_id to b_id\\n  - No clear dependency → no edge\\n\\nOutput format:\\nReturn a JSON object like:\\n\\n```json\\n{{\\n  \\\"edge\\\": true or false,\\n  \\\"from\\\": \\\"source_id\\\" or \\\"NA\\\",\\n  \\\"to\\\": \\\"target_id\\\" or \\\"NA\\\",\\n  \\\"reason\\\": \\\"Brief explanation of the dependency or lack thereof\\\"\\n}}\\n```\\n\\n- If there is a dependency, set edge: true, from as the prerequisite's ID, and to as the dependent's ID.\\n- If there is no clear prerequisite relationship, set edge: false and \\\"from\\\": \\\"NA\\\", \\\"to\\\": \\\"NA\\\" with a brief justification in reason.\\n\\nOnly base your answer on the textual meaning of the labels, and only report direct dependencies (not transitive or indirect ones).\",\n",
    "    \"user\" : \"Given the following skill indicators:\\n- a_label: {label_1}\\n- a_id: {id_1}\\n- b_label: {label_2}\\n- b_id: {id_2}\\n\\nDetermine the dependency relationship and output the JSON:\\n\\n```json\\n{{\\n  \\\"edge\\\": true or false,\\n  \\\"from\\\": \\\"source_id\\\" or \\\"NA\\\",\\n  \\\"to\\\": \\\"target_id\\\" or \\\"NA\\\",\\n  \\\"reason\\\": \\\"Brief explanation of the dependency or lack thereof\\\"\\n}}\\n```\\n\\n\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f29e6",
   "metadata": {},
   "source": [
    "### Post-processing generated outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98534d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the jsonl files\n",
    "base_path = \"raw/edge_raw_\"\n",
    "# load all jsonl files\n",
    "data = []\n",
    "for i in tqdm(range(10)):\n",
    "    with open(f\"{base_path}{i}.jsonl\", \"r\") as f:\n",
    "        data.extend(json.load(f))\n",
    "        \n",
    "#Confirming the total count\n",
    "print(f\"Total number of records: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = [o for o in data if isinstance(o['output'], dict)]\n",
    "non_dicts = [o for o in data if not isinstance(o['output'], dict)]\n",
    "len(all_dicts), len(non_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed the first line \"edge\":\" to \"edge\":\n",
    "\n",
    "data_strings = \"\"\"{'output': '```json\\n{\\n  \"edge\": false,\\n  \"from\": \"NA\",\\n  \"to\": \"NA\",\\n  \"reason\": \"While a curiosity about the world (skill a) might *benefit* from reading (skill b), enjoying reading a wide range of texts does not logically require the ability to ask questions about the world. They are in different domains (Science vs. English) and reading enjoyment is not a prerequisite for scientific inquiry. Furthermore, skill b is for an older age group, making it unlikely to depend on skill a.\"\\n}\\n```', 'id_1': 'i1060', 'id_2': 'i2635', 'label_1': 'Ask questions about the world around us and talk about how to find answers.', 'label_2': 'Enjoy reading a wide range of texts.', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Science', 'skill_2': 'English', 'subskill_1': 'Thinking and Working Scientifically', 'subskill_2': 'Reading', 'goal_1': 'Scientific enquiry: purpose and planning', 'goal_2': 'Appreciation and reflection', 'stage_1': 2, 'stage_2': 7}\n",
    "**********\n",
    "{'output': '```jsonjson\\n{\\n  \"edge\": false,\\n  \"from\": \"NA\",\\n  \"to\": \"NA\",\\n  \"reason\": \"These skills belong to entirely different domains (Humanities vs. Science) and address different cognitive areas. Understanding one\\'s worldview or others\\' does not logically necessitate understanding the physics of sound reflection, nor does the latter require the former. The age groups also suggest a lack of direct dependency, with \\'b\\' being for older children.\"\\n}\\n```', 'id_1': 'i1593', 'id_2': 'i2223', 'label_1': 'Identify aspects of their own worldviews and those of others.', 'label_2': 'Explain echoes in terms of the reflection of sound waves.', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Humanities', 'skill_2': 'Science', 'subskill_1': 'People', 'subskill_2': 'Physics', 'goal_1': 'Identity', 'goal_2': 'Light and sound', 'stage_1': 6, 'stage_2': 7}\n",
    "**********\n",
    "{'output': '```jsonjson\\n{\\n  \"edge\": false,\\n  \"from\": \"NA\",\\n  \"to\": \"NA\",\\n  \"reason\": \"Drawing a map of a local area (a skill focused on spatial reasoning and place understanding) does not logically precede or enable the ability to comment on grammatical structure in writing. These skills belong to different domains (Humanities vs. English) and target different cognitive abilities. The age groups also differ significantly, with the map-drawing skill appearing in a much younger age group.\"\\n}\\n```', 'id_1': 'i1685', 'id_2': 'i2580', 'label_1': 'Draw a simple map of their local area.', 'label_2': 'Comment on how a writer builds up detail through the grammatical structure of their sentences.', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Humanities', 'skill_2': 'English', 'subskill_1': 'Places', 'subskill_2': 'Reading', 'goal_1': 'Living places', 'goal_2': 'Grammar and punctuation', 'stage_1': 3, 'stage_2': 7}\n",
    "**********\n",
    "{'output': '```json\\n{\\n  \"\"edge\": false,\\n  \"from\": \"NA\",\\n  \"to\": \"NA\",\\n  \"reason\": \"While both skills involve data, recognizing that data *can* show information (a_id) is a much broader, more foundational skill related to data interpretation. Calculating speed (b_id) is a specific application of mathematical operations within a physics context. There\\'s no logical requirement to understand the general concept of data representation before being able to apply a specific formula. Furthermore, the age groups and developmental stages differ significantly, with \\'recognizing data\\' appearing much earlier in development.\"\\n}\\n```', 'id_1': 'i1736', 'id_2': 'i2209', 'label_1': 'Recognise that graphical and numerical data can show information about an issue.', 'label_2': 'Calculate speed (speed = distance / time).', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Global Perspectives', 'skill_2': 'Science', 'subskill_1': 'Analysis', 'subskill_2': 'Physics', 'goal_1': 'Interpreting data', 'goal_2': 'Forces and energy', 'stage_1': 2, 'stage_2': 8}\n",
    "**********\n",
    "{'output': '```jsonjson\\n{\\n  \"edge\": true,\\n  \"from\": \"i1755\",\\n  \"to\": \"i2113\",\\n  \"reason\": \"Being able to answer questions with relevant information (i1755) is a foundational skill for interpreting results and explaining conclusions (i2113). You need to be able to communicate information before you can analyze it and draw conclusions about it. The age groups also align with a developmental progression - basic information answering precedes complex scientific analysis.\"\\n}\\n```', 'id_1': 'i1755', 'id_2': 'i2113', 'label_1': 'Answer questions with relevant information about a given issue.', 'label_2': 'Make conclusions by interpreting results and explain the limitations of the conclusions.', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Global Perspectives', 'skill_2': 'Science', 'subskill_1': 'Communication', 'subskill_2': 'Thinking and Working Scientifically', 'goal_1': 'Communicating information', 'goal_2': 'Scientific enquiry: analysis, evaluation and conclusions', 'stage_1': 1, 'stage_2': 7}\n",
    "**********\n",
    "{'output': '```json\\n{\\n  \"edge\": false,\\n  \"\"from\": \"NA\",\\n  \"to\": \"NA\",\\n  \"reason\": \"These skills belong to entirely different domains (Digital Literacy vs. Chemistry) and developmental stages. Knowing about digital technology does not logically necessitate understanding chemical reactions, nor does understanding chemical reactions require knowledge of digital technology. There is no clear dependency.\"\\n}\\n```', 'id_1': 'i1871', 'id_2': 'i2191', 'label_1': 'Know that digital technology can give access to a wide variety of information.', 'label_2': 'Explain why a precipitate forms, in terms of a chemical reaction between soluble reactants forming at least one insoluble product.', 'age_group_1': '5-11', 'age_group_2': '11-14', 'skill_1': 'Digital Literacy', 'skill_2': 'Science', 'subskill_1': 'The Digital World', 'subskill_2': 'Chemistry', 'goal_1': 'The Digital World', 'goal_2': 'Changes to materials', 'stage_1': 2, 'stage_2': 7}\n",
    "**********\"\"\"\n",
    "\n",
    "# Split into individual records\n",
    "raw_records = data_strings.strip().split(\"**********\")\n",
    "parsed_outputs = []\n",
    "\n",
    "for record in raw_records:\n",
    "    if not record.strip():\n",
    "        continue\n",
    "    try:\n",
    "        # Extract the 'output' field using a regex\n",
    "        output_match = re.search(r\"'output':\\s*'(.*?)',\", record, re.DOTALL)\n",
    "        if not output_match:\n",
    "            print(\"No output found in record.\")\n",
    "            continue\n",
    "\n",
    "        raw_output = output_match.group(1)\n",
    "        \n",
    "        # Clean up bad formatting\n",
    "        cleaned = raw_output\n",
    "        cleaned = cleaned.replace(\"```jsonjson\", \"\").replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        cleaned = cleaned.strip()\n",
    "\n",
    "        # Fix bad quotes around keys if any (e.g., '\"\"edge\"' or '\"edge\":')\n",
    "        cleaned = re.sub(r'\"\"(\\w+)\"', r'\"\\1\"', cleaned)\n",
    "        cleaned = re.sub(r'\"(\\w+)\"\\s*:', r'\"\\1\":', cleaned)\n",
    "\n",
    "        # Parse JSON\n",
    "        json_obj = json.loads(cleaned)\n",
    "        parsed_outputs.append(json_obj)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse a record: {e}\")\n",
    "        print(\"Raw output was:\")\n",
    "        print(cleaned)\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "for d in range(len(non_dicts)):\n",
    "    non_dicts[d]['output'] = parsed_outputs[d]\n",
    "\n",
    "all_dicts.extend(non_dicts)\n",
    "print(len(all_dicts))\n",
    "\n",
    "edges = [o for o in all_dicts if o['output']['edge']==True]\n",
    "no_edges = [o for o in all_dicts if o['output']['edge']==False]\n",
    "print(len(edges) + len(no_edges))\n",
    "\n",
    "valid_edges = []\n",
    "invalid_edges = []\n",
    "for edge in edges:\n",
    "    given_list = [edge[\"id_1\"], edge[\"id_2\"]]\n",
    "    if edge[\"output\"][\"from\"] in given_list and edge[\"output\"][\"to\"] in given_list:\n",
    "        valid_edges.append(edge)\n",
    "    else:\n",
    "        invalid_edges.append(edge)\n",
    "print(\"Valid edges:\", len(valid_edges))\n",
    "print(\"Invalid edges:\", len(invalid_edges))\n",
    "\n",
    "for e in invalid_edges:\n",
    "    if e['output']['from'] == e['id_1']:\n",
    "        e['output']['to'] = e['id_2']\n",
    "    elif e['output']['from'] == e['id_2']:\n",
    "        e['output']['to'] = e['id_1']\n",
    "    elif e['output']['to'] == e['id_1']:\n",
    "        e['output']['from'] = e['id_2']\n",
    "    elif e['output']['to'] == e['id_2']:\n",
    "        e['output']['from'] = e['id_1']\n",
    "    else:\n",
    "        print(\"Error in edge mapping:\", e)\n",
    "        continue  \n",
    "    \n",
    "valid_edges.extend(invalid_edges)\n",
    "print(\"Total edges after fixing:\", len(valid_edges))\n",
    "\n",
    "same_nodes = []\n",
    "for i in range(len(valid_edges)):\n",
    "    if valid_edges[i][\"output\"][\"from\"] == valid_edges[i][\"output\"][\"to\"]:\n",
    "        same_nodes.append(valid_edges[i])\n",
    "        valid_edges.remove(valid_edges[i])\n",
    "\n",
    "print(\"Same nodes:\", len(same_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92816adf",
   "metadata": {},
   "source": [
    "### Add new edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph from pkl\n",
    "with open(\"./indicator_graph.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)\n",
    "    \n",
    "for i in range(len(valid_edges)):\n",
    "    DG.add_edge(valid_edges[i]['output']['from'], valid_edges[i]['output']['to'], type=\"dependency\", label=\"is prerequisite of\", reason=valid_edges[i]['output']['reason'])\n",
    "    \n",
    "# save the graph\n",
    "with open(\"./indicator_graph_edges.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DG, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55342dd3",
   "metadata": {},
   "source": [
    "## Analysis of Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372160ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph from pkl\n",
    "with open(\"./indicator_graph_edges.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of nodes in the graph:\", len(DG.nodes()))\n",
    "print(\"Total number of edges in the graph after dependency analysis:\", len(DG.edges()))\n",
    "print(\"Average degree of the graph after dependency analysis:\", sum(dict(DG.degree()).values()) / len(DG.nodes()))\n",
    "\n",
    "# Compute degree count\n",
    "degree_count = collections.Counter(dict(DG.degree()).values())\n",
    "degree_data = sorted(degree_count.items())  # List of (degree, count)\n",
    "\n",
    "# Separate into X and Y for plotting\n",
    "degrees, counts = zip(*degree_data)\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(degrees, counts, color='skyblue')\n",
    "\n",
    "# Add text labels above bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 0.5, str(height),\n",
    "             ha='center', va='bottom', fontsize=4)\n",
    "\n",
    "# Customize axes and title\n",
    "plt.xlabel(\"Node Degree\")\n",
    "plt.ylabel(\"Number of Nodes\")\n",
    "plt.title(\"Degree Count Plot\")\n",
    "plt.xticks(degrees, fontsize=4)  # Ensure all degrees are shown\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ce161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters\n",
    "age_group_in_degree = defaultdict(int)\n",
    "age_group_out_degree = defaultdict(int)\n",
    "\n",
    "for node in DG.nodes():\n",
    "    age_group = DG.nodes[node].get('age_group', 'Unknown')\n",
    "    in_deg = DG.in_degree(node)\n",
    "    out_deg = DG.out_degree(node)\n",
    "    \n",
    "    age_group_in_degree[age_group] += in_deg\n",
    "    age_group_out_degree[age_group] += out_deg\n",
    "\n",
    "# Combine and display the results\n",
    "print(f\"{'Age Group':<15} {'In-Degree':>10} {'Out-Degree':>12}\")\n",
    "print(\"-\" * 40)\n",
    "for group in sorted(set(age_group_in_degree.keys()) | set(age_group_out_degree.keys())):\n",
    "    in_deg = age_group_in_degree.get(group, 0)\n",
    "    out_deg = age_group_out_degree.get(group, 0)\n",
    "    print(f\"{group:<15} {in_deg:>10} {out_deg:>12}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dictionaries to store counts for incoming and outgoing connections\n",
    "outgoing_connections = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over each node to find outgoing and incoming connections\n",
    "for node in DG.nodes():\n",
    "    node_age_group = DG.nodes[node].get('age_group', 'Unknown')\n",
    "    \n",
    "    # Go through all outgoing neighbors of the node\n",
    "    for neighbor in DG.successors(node):\n",
    "        neighbor_age_group = DG.nodes[neighbor].get('age_group', 'Unknown')\n",
    "        \n",
    "        # Outgoing connection: node -> neighbor\n",
    "        outgoing_connections[node_age_group][neighbor_age_group] += 1\n",
    "\n",
    "# Print the Outgoing Connections Table\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(f\"{'Age Group 1':<15} {'Age Group 2':<15} {'Outgoing Connections'}\")\n",
    "print(\"-\" * 50)\n",
    "for age_group1 in sorted(outgoing_connections.keys()):\n",
    "    for age_group2, count in outgoing_connections[age_group1].items():\n",
    "        print(f\"{age_group1:<15} {age_group2:<15} {count:>20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store outgoing connection counts\n",
    "outgoing_connections = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over each node to count outgoing connections by last stage label\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "\n",
    "    for neighbor in DG.successors(node):\n",
    "        neighbor_stage = DG.nodes[neighbor].get('stage', None)\n",
    "\n",
    "        outgoing_connections[node_stage][neighbor_stage] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "conf_matrix = pd.DataFrame(outgoing_connections).fillna(0).astype(int)\n",
    "conf_matrix = conf_matrix.sort_index().T.sort_index()  # sort rows and columns\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix (Outgoing Connections by Last Stage Label):\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=True, linewidths=0.5)\n",
    "plt.title(\"Heatmap of Outgoing Connections by Last Stage Label\")\n",
    "plt.xlabel(\"Neighbor Stage Label (To)\")\n",
    "plt.ylabel(\"Node Stage Label (From)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a21e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store outgoing connection counts\n",
    "outgoing_connections = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over each node to count outgoing connections by last stage label\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('skill', None)\n",
    "\n",
    "    for neighbor in DG.successors(node):\n",
    "        neighbor_stage = DG.nodes[neighbor].get('skill', None)\n",
    "\n",
    "        outgoing_connections[node_stage][neighbor_stage] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "conf_matrix = pd.DataFrame(outgoing_connections).fillna(0).astype(int)\n",
    "conf_matrix = conf_matrix.sort_index().T.sort_index()  # sort rows and columns\n",
    "\n",
    "# Print the confusion matrix\n",
    "# print(\"\\nConfusion Matrix (Outgoing Connections by Last Stage Label):\")\n",
    "# print(conf_matrix)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=True, linewidths=0.5)\n",
    "plt.title(\"Heatmap of Outgoing Connections by Skills\")\n",
    "plt.xlabel(\"Neighbor skill (From)\")\n",
    "plt.ylabel(\"Node skill (To)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decebb85",
   "metadata": {},
   "source": [
    "## Adding Edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./indicator_graph_edges.pkl\", \"rb\") as f:\n",
    "    DG = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859a295",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbbf581",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = []\n",
    "for edge in DG.edges():\n",
    "    seed = {}\n",
    "    seed['from_id'] = edge[0]\n",
    "    seed['to_id'] = edge[1]\n",
    "    seed['from_stage'] = DG.nodes[edge[0]].get('stage')\n",
    "    seed['to_stage'] = DG.nodes[edge[1]].get('stage')\n",
    "    seed['from_skill'] = DG.nodes[edge[0]].get('skill')\n",
    "    seed['to_skill'] = DG.nodes[edge[1]].get('skill')\n",
    "    seed['from_subskill'] = DG.nodes[edge[0]].get('subskill')\n",
    "    seed['to_subskill'] = DG.nodes[edge[1]].get('subskill')\n",
    "    seed['from_age_group'] = DG.nodes[edge[0]].get('age_group')\n",
    "    seed['to_age_group'] = DG.nodes[edge[1]].get('age_group')\n",
    "    seed['from_goal'] = DG.nodes[edge[0]].get('goal')\n",
    "    seed['to_goal'] = DG.nodes[edge[1]].get('goal')\n",
    "    seed['from_label'] = DG.nodes[edge[0]].get('label')\n",
    "    seed['to_label'] = DG.nodes[edge[1]].get('label')\n",
    "    seed['reason'] = DG.edges[edge].get('reason')\n",
    "    seed_list.append(seed)\n",
    "print(len(seed_list))\n",
    "with open(\"./edge_weight_seed.jsonl\", \"w\") as f:\n",
    "    json.dump(seed_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide seed_list into 6 parts\n",
    "chunk_size = len(seed_list) // 6\n",
    "chunks = [seed_list[i:i + chunk_size] for i in range(0, len(seed_list), chunk_size)]\n",
    "# save each chunk to a separate file\n",
    "for i, chunk in enumerate(chunks):\n",
    "    with open(f\".edge_weight_seed_{i}.jsonl\", \"w\") as f:\n",
    "        json.dump(chunk, f, indent=4)\n",
    "#write a metadata file with the number of edges in each file\n",
    "metadata = {}\n",
    "for i in range(len(chunks)):\n",
    "    metadata[f\"edge_weight_seed_{i}.jsonl\"] = len(chunks[i])\n",
    "with open(\".edge_weight_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the length of the seed_list is equal to the sum of the lengths of the chunks\n",
    "total_length = sum(len(chunk) for chunk in chunks)\n",
    "print(len(seed_list) == total_length)\n",
    "#print length of each chunk\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i} length: {len(chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a56d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_p = \"You are an expert in child development, skill acquisition, and cognitive science. Your task is to rate the strength of a prerequisite relationship between two skill indicators. Each input includes:\\n- from_label and to_label: the skill indicators (already determined to be in a prerequisite relationship, where from_label is a prerequisite for to_label)\\n- Additional metadata: age groups, subskills, goals, developmental stages, and a rationale for why the edge exists.\\n\\nInstructions:\\nRate the dependency strength on a scale from 1 to 5, where:\\n- 1 = Very weak dependency (minimal or contextual support, can often be developed independently)\\n- 2 = Weak dependency (some support role, but not always required)\\n- 3 = Moderate dependency (often occurs first, but not strictly necessary)\\n- 4 = Strong dependency (usually needed before progressing)\\n- 5 = Very strong dependency (essential foundational step for the next)\\n\\nYour response should consider:\\n1. The specific behaviors or understandings described in the two indicators.\\n2. Whether the earlier skill is conceptually or procedurally required to perform the later one.\\n3. The closeness of developmental stages and subskills.\\n\\nOutput Format:\\nReturn your decision as a JSON object:\\n```json\\n{{\\n  \\\"weight\\\": [an integer from 1 to 5],\\n  \\\"reason\\\": \\\"[a brief explanation of why this weight reflects the strength of the dependency]\\\"\\n}}\\n```\"\n",
    "print(sys_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_p = \"Given the following information about a prerequisite relationship between two skill indicators:\\n\\n- from_label: {from_label}\\n- from_id: {from_id}\\n    - age group: {from_age_group}\\n    - skill: {from_skill}\\n    - subskill: {from_subskill}\\n    - goal: {from_goal}\\n    - stage: {from_stage}\\n\\n-------------------------\\n\\n- to_label: {to_label}\\n- to_id: {to_id}\\n    - age group: {to_age_group}\\n    - skill: {to_skill}\\n    - subskill: {to_subskill}\\n    - goal: {to_goal}\\n    - stage: {to_stage}\\n\\nThis relationship has already been labeled as a prerequisite edge (from_id → to_id).\\n\\nRationale for this dependency:\\n\\\"{reason}\\\"\\n\\nRate the strength of this dependency on a scale from 1 to 5.\\n\\nOutput a JSON object:\\n```json\\n{{\\n  \\\"weight\\\": [an integer from 1 to 5],\\n  \\\"reason\\\": \\\"Brief explanation of why this weight reflects the strength of the dependency\\\"\\n}}\\n```\"\n",
    "print(user_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_prompt = {\"system\": sys_p, \"user\": user_p}\n",
    "with open(\"/datadrive/pavan/az_storage/data_unorganized/skill_graph/version2/edge_weight_prompt.json\", \"w\") as f:\n",
    "    json.dump(weight_prompt, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e10c0f",
   "metadata": {},
   "source": [
    "### Post-processing generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9973c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./edge_weight_metadata.json\", \"r\") as f:\n",
    "    edge_files = json.load(f)\n",
    "\n",
    "print(edge_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i in edge_files:\n",
    "    with open(f\"./{i.replace('seed','raw')}\", \"r\") as f:\n",
    "        edges = json.load(f)\n",
    "        all_data.extend(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for j in edge_files:\n",
    "    c+=edge_files[j]\n",
    "print(c)\n",
    "\n",
    "#Confirming the total count\n",
    "print(f\"Total number of records: {len(all_data)}\")\n",
    "all_dicts = [o for o in all_data if isinstance(o['output'], dict)]\n",
    "non_dicts = [o for o in all_data if not isinstance(o['output'], dict)]\n",
    "len(all_dicts), len(non_dicts)\n",
    "\n",
    "correct_non_dicts = [{\n",
    "  \"weight\": 4,\n",
    "  \"reason\": \"While not the *only* prerequisite, being able to accurately count and understand the cardinality of numbers up to 10 is a very strong foundation for interpreting data. Drawing conclusions from data fundamentally relies on quantifying 'how much' or 'how many' – skills directly addressed by the 'Counts and answers \\\"How many?\\\"' indicator. The age gap is present, but the foundational nature of counting for data analysis makes this a strong dependency, even if further mathematical skills develop alongside data interpretation.\"\n",
    "},\n",
    "{\n",
    "  \"weight\": 4,\n",
    "  \"reason\": \"While not impossible to *begin* exploring connectives without full vocabulary mastery, a strong understanding of word meanings is crucial for truly *exploring* their function and effect. You can't analyze how clauses are connected if you don't understand what those clauses *mean*. The rationale correctly points out that understanding the individual clauses is a necessary first step, and that relies heavily on the 'from' skill. The age groups and subskills are closely aligned, reinforcing this strong dependency.\"\n",
    "},\n",
    "{\n",
    "  \"weight\": 4,\n",
    "  \"reason\": \"The ability to analyze a writer's stylistic choices (formal/informal language) fundamentally relies on first being able to understand *what* the writer is saying – the explicit meaning. You can't dissect the *effect* of language if you haven't first grasped the literal content. While some initial awareness of tone might be possible without explicit meaning exploration, a robust analysis requires it. The progression from stage 3 to stage 9 also suggests a clear developmental sequence where foundational comprehension skills are built upon.\"\n",
    "},\n",
    "{\n",
    "  \"weight\": 4,\n",
    "  \"reason\": \"The ability to reflect and evaluate (i763) is a crucial component of interpreting results in a scientific context (i1143).  Interpreting data *is* evaluating data – determining what it means, identifying patterns, and drawing conclusions. While a child might be able to *present* results without deep reflection, truly *interpreting* them requires the evaluative skills developed in i763. The shared stage (6) and age group further strengthen this dependency, suggesting they are closely linked in developmental progression.\"\n",
    "},\n",
    "{\n",
    "  \"weight\": 4,\n",
    "  \"reason\": \"The ability to articulate one's own views is very strongly linked to being able to share preferences and recommendations. While a child *could* state a preference (\\\"I like this book!\\\"), a meaningful recommendation requires explaining *why* – which directly relies on the ability to understand and express personal opinions. The stages are also adjacent (3 to 4), indicating a close developmental sequence. It's not absolutely impossible to have a preference without articulated reasoning, but the recommendation aspect necessitates it.\"\n",
    "}]\n",
    "\n",
    "for i,d in enumerate(non_dicts):\n",
    "    d['output'] = correct_non_dicts[i]\n",
    "all_dicts.extend(non_dicts)\n",
    "\n",
    "good_scores = [o for o in all_dicts if isinstance(o['output']['weight'], int)]\n",
    "bad_scores = [o for o in all_dicts if not isinstance(o['output']['weight'], int)]\n",
    "len(good_scores), len(bad_scores)\n",
    "\n",
    "for i in range(len(good_scores)):\n",
    "    DG.edges[good_scores[i]['from_id'], good_scores[i]['to_id']]['weight'] = good_scores[i]['output']['weight']\n",
    "    DG.edges[good_scores[i]['from_id'], good_scores[i]['to_id']]['weight_reason'] = good_scores[i]['output']['reason']\n",
    "    \n",
    "\n",
    "#save the graph\n",
    "with open(\"./indicator_graph_edges_weighted.pkl\", \"wb\") as f:\n",
    "    pickle.dump(DG, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store outgoing connection counts\n",
    "outgoing_connections = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over each node to count outgoing connections by last stage label\n",
    "for node in DG.nodes():\n",
    "    node_stage = DG.nodes[node].get('stage', None)\n",
    "    node_skill = DG.nodes[node].get('skill', None)\n",
    "    col = str(node_stage) + \"_\" + node_skill\n",
    "\n",
    "    for neighbor in DG.successors(node):\n",
    "        neighbor_stage = DG.nodes[neighbor].get('stage', None)\n",
    "        neighbor_skill = DG.nodes[neighbor].get('skill', None)\n",
    "        n_col = str(neighbor_stage) + \"_\" + neighbor_skill\n",
    "        if DG.edges[node, neighbor].get('weight', None) > 3:\n",
    "            outgoing_connections[col][n_col] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "conf_matrix = pd.DataFrame(outgoing_connections).fillna(0).astype(int)\n",
    "conf_matrix = conf_matrix.sort_index().T.sort_index()  # sort rows and columns\n",
    "# conf_matrix = conf_matrix / conf_matrix.sum().sum()\n",
    "# conf_matrix = conf_matrix.div(conf_matrix.sum(axis=1), axis=0)  # Normalize by row\n",
    "\n",
    "plt.figure(figsize=(24, 14))\n",
    "sns.heatmap(conf_matrix, annot=False, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, linewidths=0.5)\n",
    "plt.title(\"Heatmap of Edges\")\n",
    "plt.xlabel(\"Advanced Skill\")\n",
    "plt.ylabel(\"Prerequisite Skill\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
